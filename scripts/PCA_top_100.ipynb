{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDjd8V9xVppk"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF-ZzjcKY1eM",
        "outputId": "7fc8bed6-e849-4cf0-ab06-9bd4596592c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Map:\n",
            "0: N\n",
            "1: R\n",
            "Label 'N': 96\n",
            "Label 'R': 54\n"
          ]
        }
      ],
      "source": [
        "# load normalized data and true labels\n",
        "scaled_data = pd.read_csv('../data/GSE910_scaled_top_100.csv', index_col=0)\n",
        "top_vars = pd.read_csv('../data/_GSE910_top_100_var.csv')\n",
        "labels = pd.read_csv('../data/GSE910_labels.csv',index_col=0)\n",
        "\n",
        "# encode categorical labels to numerical codes\n",
        "labels = labels['Response'].values\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "print(\"Label Map:\")\n",
        "for encoded_value, original_label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{encoded_value}: {original_label}\")\n",
        "\n",
        "# count labels\n",
        "label_counts = {}\n",
        "\n",
        "for label in labels:\n",
        "    label_counts[label] = label_counts.get(label, 0) + 1\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label '{label}': {count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fix class imbalance\n",
        "\n",
        "# use SMOTE \n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(scaled_data, labels_encoded)\n",
        "\n",
        "# count labels after resampling\n",
        "resampled_counts = {}\n",
        "\n",
        "for label in y_resampled:\n",
        "    label_counts[label] = label_counts.get(label, 0) + 1\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Label '{label}': {count}\")\n",
        "\n",
        "print(X_resampled)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSY7GL4XZnFV",
        "outputId": "91f93b0f-c379-48ae-8ad5-861267fce8af"
      },
      "outputs": [],
      "source": [
        "# fit PCA to data\n",
        "pca = PCA(n_components=10)\n",
        "pca.fit_transform(X_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "di1an_97Z3jg",
        "outputId": "1f652d1f-978a-4755-a146-846ea20667e5"
      },
      "outputs": [],
      "source": [
        "# use elbow method on variance explained to select optimal number of principal components\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# plot explained variance against principal component\n",
        "plt.plot(range(1, len(explained_variance) + 1), pca.explained_variance_ratio_, marker='o')\n",
        "plt.xlabel('Principal Component')\n",
        "plt.xticks(np.arange(1, len(pca.explained_variance_ratio_) + 1, 1))\n",
        "plt.ylabel('Explained Variance')\n",
        "plt.title('Explained Variance by Principal Components')\n",
        "plt.show()\n",
        "\n",
        "# also check cumulative variance explained\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.title('Cumulative Variance Explained by Principle Components')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.xticks(np.arange(1, len(pca.explained_variance_ratio_) + 1, 1))\n",
        "plt.ylabel('Cumulative Variance Explained') ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AohpDjLl4rp"
      },
      "outputs": [],
      "source": [
        "# 2 principal components seems to be optimal\n",
        "pca2 = PCA(n_components=6)\n",
        "PCAreduced_data = pca2.fit_transform(X_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UQXQ3MB7_yM",
        "outputId": "c49bcd6b-bf6f-4d55-b800-c6c23cd8f84c"
      },
      "outputs": [],
      "source": [
        "# Get the loadings (coefficients) for the first two principal components\n",
        "loadings = pca2.components_[:2]\n",
        "# Get the absolute values of the loadings\n",
        "# abs_loadings = np.abs(loadings)\n",
        "# Find the indices of top features for each principal component in descending order\n",
        "top_features_indices = np.argsort(loadings, axis=1)[:, ::-1]\n",
        "# Make the column headers in scaled_data as a list\n",
        "genes = list(scaled_data.columns)\n",
        "print(genes)\n",
        "# Get the names of features corresponding to the top indices\n",
        "top_features = [genes[idx] for idx in top_features_indices.flatten()]\n",
        "print(top_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOYIDrKlASLw",
        "outputId": "93d47d4c-9919-4109-fbf5-a4c78e3bb32c"
      },
      "outputs": [],
      "source": [
        "# To find the gene names of the top contributing genes of the PCA\n",
        "top = pd.read_csv('../data/GSE910_top_100_var.csv')\n",
        "Gene1 = top.iloc[91, 0]\n",
        "print('Gene1:', Gene1)\n",
        "Gene2 = top.iloc[67, 0]\n",
        "print('Gene2:',Gene2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "rQKg2tmr4kfr",
        "outputId": "e07945f8-0883-487e-c9d7-54ff5852996c"
      },
      "outputs": [],
      "source": [
        "plt.scatter(PCAreduced_data[:, 0], PCAreduced_data[:, 1], c=y_resampled)\n",
        "plt.xlabel('First principal component')\n",
        "plt.ylabel('Second principal component')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd-x3l5EDU7F",
        "outputId": "0f56a3d6-ec94-4be6-802a-45811e79723f"
      },
      "outputs": [],
      "source": [
        "# Train a logistic regression model using the top PCAs\n",
        "logreg = sklearn.linear_model.LogisticRegression()\n",
        "logreg.fit(PCAreduced_data,y_resampled)\n",
        "y_pred = logreg.predict(PCAreduced_data)\n",
        "acc = accuracy_score(y_resampled, y_pred)\n",
        "print(\"Accuracy score of LogReg model on top PCAs:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a logistic regression model using the top 2 PCAs before optimizing hyperparameters\n",
        "X_train, X_test, y_train, y_test = train_test_split(PCAreduced_data, y_resampled, test_size = 0.3, random_state=1210)\n",
        "logreg = sklearn.linear_model.LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_train)\n",
        "training_accuracy = accuracy_score(y_pred, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_pred, y_test)\n",
        "print(\"Training accuracy before hyperparameter optimization:\", training_accuracy)\n",
        "print(\"Test set accuracy before hyperparameter optimization:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a logistic regression model using the top 2 PCAs\n",
        "logreg = sklearn.linear_model.LogisticRegression(penalty=\"l1\", C=0.1,solver='liblinear')\n",
        "\n",
        "logreg.fit(PCAreduced_data,y_resampled)\n",
        "y_pred = logreg.predict(PCAreduced_data)\n",
        "acc = accuracy_score(y_resampled, y_pred)\n",
        "print(\"Accuracy score of LogReg model on top 2 PCAs:\", acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the best hyperparameters for an L1 regularized LogReg model\n",
        "hyperparameters = {\n",
        "    'C': [0.1, 1, 10, 100, 1000],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [1000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(LogisticRegression(penalty=\"l1\"), hyperparameters,  cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train a logistic regression model using the top 2 PCAs after optimizing hyperparameters\n",
        "y_pred = best_model.predict(X_train)\n",
        "training_accuracy = accuracy_score(y_pred, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_pred, y_test)\n",
        "\n",
        "print(\"Training accuracy after hyperparameter optimization:\", training_accuracy)\n",
        "print(\"Test set accuracy after hyperparameter optimization:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cv of PCA (number of PCs) and L1 logistic regression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('pca', PCA()),\n",
        "    ('clf', LogisticRegression(penalty = 'l1'))\n",
        "\n",
        "])\n",
        "\n",
        "hyperparameters = {\n",
        "    'pca__n_components': list(range(1, 16)),\n",
        "    'clf__C': [0.1, 1, 10, 100, 1000],\n",
        "    'clf__solver': ['liblinear', 'saga'],\n",
        "    'clf__max_iter': [1000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, hyperparameters,  cv=5, scoring = 'accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best hyperparameters:\", best_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNzg5V70NatJQ0UfEmUw3Vg",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
